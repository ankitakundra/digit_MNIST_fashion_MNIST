{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "digit_recognition.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ankitakundra/pytorch_digit_recognition/blob/master/digit_recognition.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DhzYDLHUTnZE",
        "colab_type": "code",
        "outputId": "39a42250-dd22-4b07-f92c-d1efc9b9a71f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        }
      },
      "source": [
        "import torch\n",
        "import torchvision \n",
        "from torchvision import transforms,datasets\n",
        "train = datasets.MNIST(\"\",train = True, download = True, transform = transforms.Compose([transforms.ToTensor()]))\n",
        "\n",
        "test = datasets.MNIST(\"\",train = False, download = True, transform = transforms.Compose([transforms.ToTensor()]))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r0it [00:00, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to MNIST/raw/train-images-idx3-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "9920512it [00:01, 9039771.46it/s]                            \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting MNIST/raw/train-images-idx3-ubyte.gz to MNIST/raw\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "  0%|          | 0/28881 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "32768it [00:00, 136498.61it/s]           \n",
            "  0%|          | 0/1648877 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting MNIST/raw/train-labels-idx1-ubyte.gz to MNIST/raw\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "1654784it [00:00, 2298610.91it/s]                           \n",
            "0it [00:00, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting MNIST/raw/t10k-images-idx3-ubyte.gz to MNIST/raw\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "8192it [00:00, 51166.88it/s]            "
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting MNIST/raw/t10k-labels-idx1-ubyte.gz to MNIST/raw\n",
            "Processing...\n",
            "Done!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gRq-TQIQU994",
        "colab_type": "code",
        "outputId": "fe3bce74-df4d-42b5-bcc6-27f1582e8852",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "trainset = torch.utils.data.DataLoader(train,batch_size =10, shuffle = True)\n",
        "testset = torch.utils.data.DataLoader(test,batch_size =10, shuffle = True)\n",
        "\n",
        "for data in trainset:\n",
        "  print(data)\n",
        "  break\n",
        "y = data[1][0]\n",
        "print(y)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[tensor([[[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]]]), tensor([7, 0, 3, 6, 9, 9, 6, 5, 5, 3])]\n",
            "tensor(7)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V9bnvJ88LQS0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hrxbKTluKu7p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.imshow(data[0][0].view(28,28))\n",
        "plt.show()\n",
        "print(data[0][0].shape)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hBpJ2D2BOIyA",
        "colab_type": "code",
        "outputId": "4124d447-a4ea-4643-f13d-385de418a94c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "total = 0\n",
        "counter_dict  = {0:0, 1:0, 2:0, 3:0,4:0,5:0,6:0,7:0,8:0,9:0}\n",
        "for data in trainset:\n",
        "  xs,ys = data\n",
        "  for y in ys:\n",
        "    counter_dict[int(y)]+=1\n",
        "    total+=1\n",
        "    \n",
        "print(counter_dict)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{0: 5923, 1: 6742, 2: 5958, 3: 6131, 4: 5842, 5: 5421, 6: 5918, 7: 6265, 8: 5851, 9: 5949}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ao00N4XnPLac",
        "colab_type": "code",
        "outputId": "92efeb0a-9fe4-41d9-e8e6-a4c5cb4fd982",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        }
      },
      "source": [
        "for i in counter_dict:\n",
        "  print(f\"{i}: {counter_dict[i]/total * 100}\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0: 9.871666666666666\n",
            "1: 11.236666666666666\n",
            "2: 9.93\n",
            "3: 10.218333333333334\n",
            "4: 9.736666666666666\n",
            "5: 9.035\n",
            "6: 9.863333333333333\n",
            "7: 10.441666666666666\n",
            "8: 9.751666666666667\n",
            "9: 9.915000000000001\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OACnp4FtRAPD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JhoUHbtSRI19",
        "colab_type": "code",
        "outputId": "7c933f55-7584-4a11-8970-659f9edc0018",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        }
      },
      "source": [
        "class Net(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.fc1 = nn.Linear(784,64)\n",
        "    self.fc2 = nn.Linear(64,64)\n",
        "    self.fc3 = nn.Linear(64,64)\n",
        "    self.fc4 = nn.Linear(64,10)\n",
        "    \n",
        "  def forward(self,x):\n",
        "    x = F.relu(self.fc1(x))\n",
        "    x = F.relu(self.fc2(x))\n",
        "    x = F.relu(self.fc3(x))\n",
        "    x = self.fc4(x)\n",
        " \n",
        "    return F.log_softmax(x,dim = 1)\n",
        "\n",
        "net = Net()\n",
        "print(net)\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Net(\n",
            "  (fc1): Linear(in_features=784, out_features=64, bias=True)\n",
            "  (fc2): Linear(in_features=64, out_features=64, bias=True)\n",
            "  (fc3): Linear(in_features=64, out_features=64, bias=True)\n",
            "  (fc4): Linear(in_features=64, out_features=10, bias=True)\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8hSErQ9uVGcF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "\n",
        "\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LdhUIv64Yt29",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X  = torch.rand((28,28))\n",
        "X = X.view(1,28*28)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xbPNTzuPaX5a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "output = net(X)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3TM2U6VgbHo5",
        "colab_type": "code",
        "outputId": "528c6d93-62b9-4e58-85d7-983543010d16",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "source": [
        "output"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-2.2236, -2.3153, -2.3245, -2.3740, -2.2748, -2.3066, -2.3557, -2.2610,\n",
              "         -2.2573, -2.3435]], grad_fn=<LogSoftmaxBackward>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8GuFME1SdYyj",
        "colab_type": "code",
        "outputId": "cc870dd4-1555-4746-e6f1-a305ba5e1268",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "import torch.optim as optim\n",
        "optimizer = optim.Adam(net.parameters(), lr = 0.001)\n",
        "\n",
        "EPOCHS = 3\n",
        "for epoch in range(EPOCHS):\n",
        "  for data in trainset:\n",
        "    X,y = data\n",
        "    net.zero_grad()\n",
        "    output = net(X.view(-1,28*28))\n",
        "    loss = F.nll_loss(output,y)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "  print(loss)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(0.1018, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0090, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0097, grad_fn=<NllLossBackward>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "65AnIM5zjtWc",
        "colab_type": "code",
        "outputId": "4d475224-db6e-43c1-c6a4-b6dfd0a08a07",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "  for data in trainset:\n",
        "    X,y = data\n",
        "    output = net(X.view(-1,28*28))\n",
        "    for idx,i in enumerate(output):\n",
        "      if torch.argmax(i )== y[idx]:\n",
        "        correct +=1\n",
        "      total +=1\n",
        "      \n",
        "print(\"Accuracy: \",round(correct/total,3))\n",
        "                      "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy:  0.978\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ur_JNMnnnZzY",
        "colab_type": "code",
        "outputId": "762b15f3-6a4e-40af-d43d-14858e7fa9ea",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.imshow(X[2].view(28,28))\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\noAg/EBThB4Ii/EBQhB8IivADQf0/uMK4ctzW/JUAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xuHpK7Q2njBn",
        "colab_type": "code",
        "outputId": "06e5ecd3-13ce-4b61-b540-92735e49907a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "print(torch.argmax(net(X[2].view(-1,784))[0]))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(0)\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}